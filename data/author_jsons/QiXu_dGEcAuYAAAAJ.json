[
  {
    "year": 2025,
    "title": "Dual Selective Gleason Pattern-Aware Multiple Instance Learning for Grade Group Prediction in Histopathology Images",
    "abstract": "The Gleason Grade Group is the gold standard for diagnosing and prognosticating prostate cancer. Existing multiple instance learning (MIL) methods for Grade Group classification have overlooked domain-specific knowledge that the Grade Group is collaboratively determined by different Gleason Patterns, limiting their performance. In this study, we propose DSPA-MIL, a Dual Selective Gleason Pattern-Aware MIL model for patient-level Grade Group prediction. Our approach incorporates a dual selective instance aggregation strategy, combining selective aggregator tokens and patch-level Gleason pattern expert concept-guided aggregation. Furthermore, to effectively utilize patient-level Grade Group expert concepts, we introduce a knowledge-distillation-based framework for training and inference, enabling accurate Grade Group score prediction. Experimental results on five datasets comprising 10,809 whole …",
    "link": "https://link.springer.com/chapter/10.1007/978-3-032-05182-0_19"
  },
  {
    "year": 2025,
    "title": "Underwater optical object detection in the era of artificial intelligence: current, challenge, and future",
    "abstract": "Underwater optical object detection (UOD), aiming at identifying and localising objects in underwater optical images or videos, presents significant challenges due to the optical distortion, water turbidity, and changing illumination in underwater scenes. In recent years, artificial intelligence (AI) based methods, especially deep learning methods, have shown promising performance in UOD. To further facilitate future advancements, we comprehensively study AI-based UOD. In this survey, we first categorise existing algorithms into traditional machine learning-based methods and deep learning-based methods, and summarise them by considering learning strategies, experimental datasets, learning stages, employed features or techniques, and underlying frameworks. Next, we discuss the potential challenges and suggest possible solutions and new directions. We also perform both quantitative and qualitative …",
    "link": "https://dl.acm.org/doi/abs/10.1145/3759243"
  },
  {
    "year": 2025,
    "title": "Underwater object detection in the era of artificial intelligence: Current, challenge, and future",
    "abstract": "Underwater object detection (UOD), aiming to identify and localise the objects in underwater images or videos, presents significant challenges due to the optical distortion, water turbidity, and changing illumination in underwater scenes. In recent years, artificial intelligence (AI) based methods, especially deep learning methods, have shown promising performance in UOD. To further facilitate future advancements, we comprehensively study AI-based UOD. In this survey, we first categorise existing algorithms into traditional machine learning-based methods and deep learning-based methods, and summarise them by considering learning strategy, experimental dataset, utilised features or frameworks, and learning stage. Next, we discuss the potential challenges and suggest possible solutions and new directions. We also perform both quantitative and qualitative evaluations of mainstream algorithms across multiple benchmark datasets by considering the diverse and biased experimental setups. Finally, we introduce two off-the-shelf detection analysis tools, Diagnosis and TIDE, which well-examine the effects of object characteristics and various types of errors on detectors. These tools help identify the strengths and weaknesses of detectors, providing insigts for further improvement. The source codes, trained models, utilised datasets, detection results, and detection analysis tools are public available at \\url{https://github.com/LongChenCV/UODReview}, and will be regularly updated.",
    "link": "https://arxiv.org/abs/2410.05577"
  },
  {
    "year": 2025,
    "title": "Spiking Neural Networks with Temporal Attention-Guided Adaptive Fusion for imbalanced Multi-modal Learning",
    "abstract": "Multimodal spiking neural networks (SNNs) hold significant potential for energy-efficient sensory processing but face critical challenges in modality imbalance and temporal misalignment. Current approaches suffer from uncoordinated convergence speeds across modalities and static fusion mechanisms that ignore time-varying cross-modal interactions. We propose the temporal attention-guided adaptive fusion framework for multimodal SNNs with two synergistic innovations: 1) The Temporal Attention-guided Adaptive Fusion (TAAF) module that dynamically assigns importance scores to fused spiking features at each timestep, enabling hierarchical integration of temporally heterogeneous spike-based features; 2) The temporal adaptive balanced fusion loss that modulates learning rates per modality based on the above attention scores, preventing dominant modalities from monopolizing optimization. The proposed framework implements adaptive fusion, especially in the temporal dimension, and alleviates the modality imbalance during multimodal learning, mimicking cortical multisensory integration principles. Evaluations on CREMA-D, AVE, and EAD datasets demonstrate state-of-the-art performance (77.55%, 70.65% and 98.65% accuracy, respectively) with energy efficiency. The system resolves temporal misalignment through learnable time-warping operations and faster modality convergence coordination than baseline SNNs. This work establishes a new paradigm for temporally coherent multimodal learning in neuromorphic systems, bridging the gap between biological sensory processing and efficient machine intelligence.mfp",
    "link": "https://dl.acm.org/doi/abs/10.1145/3746027.3755622"
  },
  {
    "year": 2025,
    "title": "Advanced SpikingYOLOX: Extending Spiking Neural Network on Object Detection with Spike-based Partial Self-Attention and 2D-Spiking Transformer",
    "abstract": "Brain-inspired Spiking Neural Networks (SNNs) have garnered significant attention due to their bio-plausibility and low power consumption advantages compared to Artificial Neural Networks (ANNs). However, the application of SNN in computer vision remains limited, primarily due to their inferior performance. In this work, we aim to bridge the performance gap between ANNs and SNNs in object detection by our Advanced SpikingYOLOX. The proposed approach extends the SpikingYOLOX with two key innovations: PSA-SNN and 2D-Spiking Transformer, both designed to enhance object detection performance. PSA-SNN extends spike-based self-attention by incorporating high-speed partial self-attention with an SNN-based 2D-Spiking Transformer in the deepest layer of the backbone, significantly improving feature extraction. The 2D-Spiking Transformer redefines the role of spiking neurons in Transformer sequences (Key, Query, Value), demonstrating that applying an additional spiking layer solely to the Value sequence yields the best performance while maintaining computational efficiency in spike-driven Transformers. We conduct extensive experiments on static images and the Advanced SpikingYOLOX achieves state-of-the-art performance among other SNN-based object detection methods. This work paves the way for more advanced SNN applications in object detection and broader computer vision tasks.",
    "link": "https://dl.acm.org/doi/abs/10.1145/3746027.3754854"
  },
  {
    "year": 2025,
    "title": "Predicting Radiation Therapy Response based on Dynamic Temporal Feature Difference Fusion from Longitudinal MRI",
    "abstract": "Abstract unavailable. This publication does not provide a summary using scholarly.",
    "link": ""
  },
  {
    "year": 2025,
    "title": "Efficient ANN-SNN Conversion with Error Compensation Learning",
    "abstract": "Artificial neural networks (ANNs) have demonstrated outstanding performance in numerous tasks, but deployment in resource-constrained environments remains a challenge due to their high computational and memory requirements. Spiking neural networks (SNNs) operate through discrete spike events and offer superior energy efficiency, providing a bio-inspired alternative. However, current ANN-to-SNN conversion often results in significant accuracy loss and increased inference time due to conversion errors such as clipping, quantization, and uneven activation. This paper proposes a novel ANN-to-SNN conversion framework based on error compensation learning. We introduce a learnable threshold clipping function, dual-threshold neurons, and an optimized membrane potential initialization strategy to mitigate the conversion error. Together, these techniques address the clipping error through adaptive thresholds, dynamically reduce the quantization error through dual-threshold neurons, and minimize the non-uniformity error by effectively managing the membrane potential. Experimental results on CIFAR-10, CIFAR-100, ImageNet datasets show that our method achieves high-precision and ultra-low latency among existing conversion methods. Using only two time steps, our method significantly reduces the inference time while maintains competitive accuracy of 94.75% on CIFAR-10 dataset under ResNet-18 structure. This research promotes the practical application of SNNs on low-power hardware, making efficient real-time processing possible.",
    "link": "https://arxiv.org/abs/2506.01968"
  },
  {
    "year": 2025,
    "title": "Hybrid Spiking Vision Transformer for Object Detection with Event Cameras",
    "abstract": "Event-based object detection has gained increasing attention due to its advantages such as high temporal resolution, wide dynamic range, and asynchronous address-event representation. Leveraging these advantages, Spiking Neural Networks (SNNs) have emerged as a promising approach, offering low energy consumption and rich spatiotemporal dynamics. To further enhance the performance of event-based object detection, this study proposes a novel hybrid spike vision Transformer (HsVT) model. The HsVT model integrates a spatial feature extraction module to capture local and global features, and a temporal feature extraction module to model time dependencies and long-term patterns in event sequences. This combination enables HsVT to capture spatiotemporal features, improving its capability to handle complex event-based object detection tasks. To support research in this area, we developed and publicly released The Fall Detection Dataset as a benchmark for event-based object detection tasks. This dataset, captured using an event-based camera, ensures facial privacy protection and reduces memory usage due to the event representation format. We evaluated the HsVT model on GEN1 and Fall Detection datasets across various model sizes. Experimental results demonstrate that HsVT achieves significant performance improvements in event detection with fewer parameters.",
    "link": "https://arxiv.org/abs/2505.07715"
  },
  {
    "year": 2025,
    "title": "Self-cross Feature based Spiking Neural Networks for Efficient Few-shot Learning",
    "abstract": "Deep neural networks (DNNs) excel in computer vision tasks, especially, few-shot learning (FSL), which is increasingly important for generalizing from limited examples. However, DNNs are computationally expensive with scalability issues in real world. Spiking Neural Networks (SNNs), with their event-driven nature and low energy consumption, are particularly efficient in processing sparse and dynamic data, though they still encounter difficulties in capturing complex spatiotemporal features and performing accurate cross-class comparisons. To further enhance the performance and efficiency of SNNs in few-shot learning, we propose a few-shot learning framework based on SNNs, which combines a self-feature extractor module and a cross-feature contrastive module to refine feature representation and reduce power consumption. We apply the combination of temporal efficient training loss and InfoNCE loss to optimize the temporal dynamics of spike trains and enhance the discriminative power. Experimental results show that the proposed FSL-SNN significantly improves the classification performance on the neuromorphic dataset N-Omniglot, and also achieves competitive performance to ANNs on static datasets such as CUB and miniImageNet with low power consumption.",
    "link": "https://arxiv.org/abs/2505.07921"
  },
  {
    "year": 2025,
    "title": "Enhancing Graph Contrastive Learning for Protein Graphs from Perspective of Invariance",
    "abstract": "Graph Contrastive Learning (GCL) improves Graph Neural Network (GNN)-based protein representation learning by enhancing its generalization and robustness. Existing GCL approaches for protein representation learning rely on 2D topology, where graph augmentation is solely based on topological features, ignoring the intrinsic biological properties of proteins. Besides, 3D structure-based protein graph augmentation remains unexplored, despite proteins inherently exhibiting 3D structures. To bridge this gap, we propose novel biology-aware graph augmentation strategies from the perspective of invariance and integrate them into the protein GCL framework. Specifically, we introduce Functional Community Invariance (FCI)-based graph augmentation, which employs spectral constraints to preserve topology-driven community structures while incorporating residue-level chemical similarity as edge weights to guide edge sampling and maintain functional communities. Furthermore, we propose 3D Protein Structure Invariance (3-PSI)-based graph augmentation, leveraging dihedral angle perturbations and secondary structure rotations to retain critical 3D structural information of proteins while diversifying graph views. Extensive experiments on four different protein-related tasks demonstrate the superiority of our proposed GCL protein representation learning framework.",
    "link": "https://openreview.net/forum?id=g2hucDbOJt"
  },
  {
    "year": 2025,
    "title": "TS-SNN: Temporal Shift Module for Spiking Neural Networks",
    "abstract": "Spiking Neural Networks (SNNs) are increasingly recognized for their biological plausibility and energy efficiency, positioning them as strong alternatives to Artificial Neural Networks (ANNs) in neuromorphic computing applications. SNNs inherently process temporal information by leveraging the precise timing of spikes, but balancing temporal feature utilization with low energy consumption remains a challenge. In this work, we introduce Temporal Shift module for Spiking Neural Networks (TS-SNN), which incorporates a novel Temporal Shift (TS) module to integrate past, present, and future spike features within a single timestep via a simple yet effective shift operation. A residual combination method prevents information loss by integrating shifted and original features. The TS module is lightweight, requiring only one additional learnable parameter, and can be seamlessly integrated into existing architectures with minimal additional computational cost. TS-SNN achieves state-of-the-art performance on benchmarks like CIFAR-10 (96.72%), CIFAR-100 (80.28%), and ImageNet (70.61%) with fewer timesteps, while maintaining low energy consumption. This work marks a significant step forward in developing efficient and accurate SNN architectures.",
    "link": "https://arxiv.org/abs/2505.04165"
  },
  {
    "year": 2025,
    "title": "Generic-to-Personalised Learning for Multimodal Image Synthesis with Bidirectional Variational GAN",
    "abstract": "Abstract unavailable. This publication does not provide a summary using scholarly.",
    "link": ""
  },
  {
    "year": 2025,
    "title": "Context gating in spiking neural networks: Achieving lifelong learning through integration of local and global plasticity",
    "abstract": "Humans learn multiple tasks in succession with minimal mutual interference, through the context gating mechanism in the prefrontal cortex (PFC). The brain-inspired models of spiking neural networks (SNN) have drawn massive attention for their energy efficiency and biological plausibility. To overcome catastrophic forgetting when learning multiple tasks in sequence, current SNN models for lifelong learning focus on memory reserving or regularization-based modification, while lacking SNN to replicate human experimental behavior. Inspired by biological context-dependent gating mechanisms found in PFC, we propose SNN with context gating trained by the local plasticity rule (CG-SNN) for lifelong learning. The iterative training between global and local plasticity for task units is designed to strengthen the connections between task neurons and hidden neurons and preserve the multi-task relevant information. The …",
    "link": "https://www.sciencedirect.com/science/article/pii/S0950705125000474"
  },
  {
    "year": 2025,
    "title": "ODA-GAN: Orthogonal Decoupling Alignment GAN Assisted by Weakly-supervised Learning for Virtual Immunohistochemistry Staining",
    "abstract": "Recently, virtual staining has emerged as a promising alternative to revolutionize histological staining by digitally generating stains. However, most existing methods suffer from the curse of staining unreality and unreliability. In this paper, we propose the Orthogonal Decoupling Alignment Generative Adversarial Network (ODA-GAN) for unpaired virtual immunohistochemistry (IHC) staining. Our approach is based on the assumption that an image consists of IHC staining-related features, which influence staining distribution and intensity, and staining-unrelated features, such as tissue morphology. Leveraging a pathology foundation model, we first develop a weakly-supervised segmentation pipeline as an alternative to expert annotations. We introduce an Orthogonal MLP (O-MLP) module to project image features into an orthogonal space, decoupling them into staining-related and unrelated components. Additionally, we propose a Dual-stream PatchNCE (DPNCE) loss to resolve contrastive learning contradictions in the staining-related space, thereby enhancing staining accuracy. To further improve realism, we introduce a Multi-layer Domain Alignment (MDA) module to bridge the domain gap between generated and real IHC images. Evaluations on three benchmark datasets show that our ODA-GAN reaches state-of-the-art (SOTA) performance. Our source code is available at https://github.com/ittong/ODA-GAN.",
    "link": "https://openaccess.thecvf.com/content/CVPR2025/html/Wang_ODA-GAN_Orthogonal_Decoupling_Alignment_GAN_Assisted_by_Weakly-supervised_Learning_for_CVPR_2025_paper.html"
  },
  {
    "year": 2025,
    "title": "Temporal Separation with Entropy Regularization for Knowledge Distillation in Spiking Neural Networks",
    "abstract": "Spiking Neural Networks (SNNs), inspired by the human brain, offer significant computational efficiency through discrete spike-based information transfer. Despite their potential to reduce inference energy consumption, a performance gap persists between SNNs and Artificial Neural Networks (ANNs), primarily due to current training methods and inherent model limitations. While recent research has aimed to enhance SNN learning by employing knowledge distillation (KD) from ANN teacher networks, traditional distillation techniques often overlook the distinctive spatiotemporal properties of SNNs, thus failing to fully leverage their advantages. To overcome these challenge, we propose a novel logit distillation method characterized by temporal separation and entropy regularization. This approach improves existing SNN distillation techniques by performing distillation learning on logits across different time steps, rather than merely on aggregated output features. Furthermore, the integration of entropy regularization stabilizes model optimization and further boosts the performance. Extensive experimental results indicate that our method surpasses prior SNN distillation strategies, whether based on logit distillation, feature distillation, or a combination of both. Our project is available at https://github.com/yukairong/TSER.",
    "link": "https://openaccess.thecvf.com/content/CVPR2025/html/Yu_Temporal_Separation_with_Entropy_Regularization_for_Knowledge_Distillation_in_Spiking_CVPR_2025_paper.html"
  },
  {
    "year": 2025,
    "title": "STAA-SNN: Spatial-Temporal Attention Aggregator for Spiking Neural Networks",
    "abstract": "Spiking Neural Networks (SNNs) have gained significant attention due to their biological plausibility and energy efficiency, making them promising alternatives to Artificial Neural Networks (ANNs). However, the performance gap between SNNs and ANNs remains a substantial challenge hindering the widespread adoption of SNNs. In this paper, we propose a Spatial-Temporal Attention Aggregator SNN (STAA-SNN) framework, which dynamically focuses on and captures both spatial and temporal dependencies. First, we introduce a spike-driven self-attention mechanism specifically designed for SNNs. Additionally, we pioneeringly incorporate position encoding to integrate latent temporal relationships into the incoming features. For spatial-temporal information aggregation, we employ step attention to selectively amplify relevant features to variant steps. Finally, we implement a time-step random dropout strategy to avoid local optima. The framework demonstrates exceptional performance across diverse datasets and exhibits strong generalization capabilities. Notably, STAA-SNN achieves state-of-the-art results on neuromorphic datasets CIFAR10-DVS of 82.10% and with performances of 97.14%, 82.05% and 70.40% on the static datasets CIFAR-10, CIFAR-100 and ImageNet, respectively. Furthermore, this model exhibits improved performance ranging from 0.33% to 2.80% with fewer time steps.",
    "link": "https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_STAA-SNN_Spatial-Temporal_Attention_Aggregator_for_Spiking_Neural_Networks_CVPR_2025_paper.html"
  },
  {
    "year": 2025,
    "title": "Temporal spiking generative adversarial networks for heading direction decoding",
    "abstract": "The spike-based neuronal responses within the ventral intraparietal area (VIP) exhibit intricate spatial and temporal dynamics in the posterior parietal cortex, presenting decoding challenges such as limited data availability at the biological population level. The practical difficulty in collecting VIP neuronal response data hinders the application of sophisticated decoding models. To address this challenge, we propose a unified spike-based decoding framework leveraging spiking neural networks (SNNs) for both generative and decoding purposes, for their energy efficiency and suitability for neural decoding tasks. We propose the Temporal Spiking Generative Adversarial Networks (T-SGAN), a model based on a spiking transformer, to generate synthetic time-series data reflecting the neuronal response of VIP neurons. T-SGAN incorporates temporal segmentation to reduce the temporal dimension length, while spatial …",
    "link": "https://www.sciencedirect.com/science/article/pii/S0893608024009043"
  },
  {
    "year": 2025,
    "title": "Improving the Sparse Structure Learning of Spiking Neural Networks from the View of Compression Efficiency",
    "abstract": "The human brain utilizes spikes for information transmission and dynamically reorganizes its network structure to boost energy efficiency and cognitive capabilities throughout its lifespan. Drawing inspiration from this spike-based computation, Spiking Neural Networks (SNNs) have been developed to construct event-driven models that emulate this efficiency. Despite these advances, deep SNNs continue to suffer from over-parameterization during training and inference, a stark contrast to the brain's ability to self-organize. Furthermore, existing sparse SNNs are challenged by maintaining optimal pruning levels due to a static pruning ratio, resulting in either under- or over-pruning. In this paper, we propose a novel two-stage dynamic structure learning approach for deep SNNs, aimed at maintaining effective sparse training from scratch while optimizing compression efficiency. The first stage evaluates the compressibility of existing sparse subnetworks within SNNs using the PQ index, which facilitates an adaptive determination of the rewiring ratio for synaptic connections based on data compression insights. In the second stage, this rewiring ratio critically informs the dynamic synaptic connection rewiring process, including both pruning and regrowth. This approach significantly improves the exploration of sparse structure training in deep SNNs, adapting sparsity dynamically from the point view of compression efficiency. Our experiments demonstrate that this sparse training approach not only aligns with the performance of current deep SNNs models but also significantly improves the efficiency of compressing sparse SNNs. Crucially, it preserves the advantages of initiating training with sparse models and offers a promising solution for implementing edge AI on neuromorphic hardware.",
    "link": "https://arxiv.org/abs/2502.13572"
  },
  {
    "year": 2025,
    "title": "Performer: A High-Performance Global-Local Model-Augmented with Dual Network Interaction Mechanism",
    "abstract": "In deep learning, Convolutional Neural Networks (CNNs) focus on local information through convolutional kernels, while transformers attend to global information using self-attention mechanisms. The union of these distinct approaches enables a more comprehensive extraction of image features. However, the feature map dimensions of CNN and Transformer differ, leading to dimension mismatch issues when combining these architectures. Additionally, the parameter size of the hybrid model integrating both architectures remains large, making it difficult to train. To further augmenting the interpretation of complex image patterns, we present Performer, a dual-network architecture that seamlessly combines CNNs and transformers, resulting in a novel and efficient representation learning model. In the Performer model, we innovate by devising a unique interaction methodology for CNN and transformer architectures to …",
    "link": "https://ieeexplore.ieee.org/abstract/document/10806585/"
  },
  {
    "year": 2025,
    "title": "FSTA-SNN:Frequency-based Spatial-Temporal Attention Module for Spiking Neural Networks",
    "abstract": "Spiking Neural Networks (SNNs) are emerging as a promising alternative to Artificial Neural Networks (ANNs) due to their inherent energy efficiency. Owing to the inherent sparsity in spike generation within SNNs, the in-depth analysis and optimization of intermediate output spikes are often neglected. This oversight significantly restricts the inherent energy efficiency of SNNs and diminishes their advantages in spatiotemporal feature extraction, resulting in a lack of accuracy and unnecessary energy expenditure. In this work, we analyze the inherent spiking characteristics of SNNs from both temporal and spatial perspectives. In terms of spatial analysis, we find that shallow layers tend to focus on learning vertical variations, while deeper layers gradually learn horizontal variations of features. Regarding temporal analysis, we observe that there is not a significant difference in feature learning across different time steps. This suggests that increasing the time steps has limited effect on feature learning. Based on the insights derived from these analyses, we propose a Frequency-based Spatial-Temporal Attention (FSTA) module to enhance feature learning in SNNs. This module aims to improve the feature learning capabilities by suppressing redundant spike features. The experimental results indicate that the introduction of the FSTA module significantly reduces the spike firing rate of SNNs, demonstrating superior performance compared to state-of-the-art baselines across multiple datasets.",
    "link": "https://ojs.aaai.org/index.php/AAAI/article/view/34377"
  },
  {
    "year": 2025,
    "title": "ALADE-SNN: Adaptive Logit Alignment in Dynamically Expandable Spiking Neural Networks for Class Incremental Learning",
    "abstract": "Inspired by the human brain's ability to adapt to new tasks without erasing prior knowledge, we develop spiking neural networks (SNNs) with dynamic structures for Class Incremental Learning (CIL). Our analytical experiments reveal that limited datasets introduce biases in logits distributions among tasks. Fixed features from frozen past-task extractors can cause overfitting and hinder the learning of new tasks. To address these challenges, we propose the ALADE-SNN framework, which includes adaptive logit alignment for balanced feature representation and OtoN suppression to manage weights mapping frozen old features to new classes during training, releasing them during fine-tuning. This approach dynamically adjusts the network architecture based on analytical observations, improving feature extraction and balancing performance between new and old tasks. Experiment results show that ALADE-SNN achieves an average incremental accuracy of 75.42 ± 0.74% on the CIFAR100-B0 dataset over 10 incremental steps. ALADE-SNN not only matches the performance of DNN-based methods but also surpasses state-of-the-art SNN-based continual learning algorithms. This advancement enhances continual learning in neuromorphic computing, offering a brain-inspired, energy-efficient solution for real-time data processing.",
    "link": "https://ojs.aaai.org/index.php/AAAI/article/view/34171"
  },
  {
    "year": 2025,
    "title": "Multi-View Incremental Learning with Structured Hebbian Plasticity for Enhanced Fusion Efficiency",
    "abstract": "The rapid evolution of multimedia technology has revolutionized human perception, paving the way for multi-view learning. However, traditional multi-view learning approaches are tailored for scenarios with fixed data views, falling short of emulating the intricate cognitive procedures of the human brain processing signals sequentially. Our cerebral architecture seamlessly integrates sequential data through intricate feed-forward and feedback mechanisms. In stark contrast, traditional methods struggle to generalize effectively when confronted with data spanning diverse domains, highlighting the need for innovative strategies that can mimic the brain's adaptability and dynamic integration capabilities. In this paper, we propose a bio-neurologically inspired multi-view incremental framework named MVIL aimed at emulating the brain's fine-grained fusion of sequentially arriving views. MVIL lies two fundamental modules: structured Hebbian plasticity and synaptic partition learning. The structured Hebbian plasticity reshapes the structure of weights to express the high correlation between view representations, facilitating a fine-grained fusion of view representations. Moreover, synaptic partition learning is efficient in alleviating drastic changes in weights and also retaining old knowledge by inhibiting partial synapses. These modules bionically play a central role in reinforcing crucial associations between newly acquired information and existing knowledge repositories, thereby enhancing the network's capacity for generalization. Experimental results on six benchmark datasets show MVIL's effectiveness over state-of-the-art methods.",
    "link": "https://ojs.aaai.org/index.php/AAAI/article/view/32115"
  },
  {
    "year": 2025,
    "title": "BIG-FUSION: Brain-Inspired Global-Local Context Fusion Framework for Multimodal Emotion Recognition in Conversations",
    "abstract": "Considering the importance of capturing both global conversational topics and local speaker dependencies for multimodal emotion recognition in conversations, current approaches first utilize sequence models like Transformer to extract global context information, then apply Graph Neural Networks to model local speaker dependencies for local context information extraction, coupled with Graph Contrastive Learning (GCL) to enhance node representation learning. However, this sequential design introduces potential biases: the extracted global context information inevitably influences subsequent processing, compromising the independence and diversity of the original local features; current graph augmentation methods in GCL cannot consider both global and local context information in conversations to evaluate the node importance, hindering the learning of key information. Inspired by the human brain excels at handling complex tasks by efficiently integrating local and global information processing mechanisms, we propose an aligned global-local context fusion framework for sequence-based design to address these problems. This design includes a dual-attention Transformer and a dual-evaluation method for graph augmentation in GCL. The dual-attention Transformer combines global attention for overall context extraction with sliding-window attention for local context capture, both enhanced by spiking neuron dynamics. The dual-evaluation method in GCL comprises global importance evaluation to identify nodes crucial for overall conversation context, and local importance evaluation to detect nodes significant for local semantics, generating augmented graph views that preserve both global and local information. This approach ensures balanced information processing throughout the pipeline, enhancing biological plausibility and achieving superior emotion recognition.",
    "link": "https://ojs.aaai.org/index.php/AAAI/article/view/32149"
  },
  {
    "year": 2025,
    "title": "SpikingYOLOX: Improved YOLOX Object Detection with Fast Fourier Convolution and Spiking Neural Networks",
    "abstract": "In recent years, with the advancements in brain science, spiking neural networks (SNNs) have garnered significant attention. SNNs can generate spikes that mimic the function of neurons transmission in humans brain, thereby significantly reducing computational costs by the event-driven nature during training. While deep SNNs have shown impressive performance on classification tasks, they still face challenges in more complex tasks such as object detection. In this paper, we propose SpikingYOLOX, extending the structure of the original YOLOX by introducing signed spiking neurons and fast Fourier convolution (FFC). The designed ternary signed spiking neurons could generate three kinds of spikes to obtain more robust features in the deep layer of the backbone. Meanwhile, we integrate FFC with SNN modules to enhance object detection performance, because its global receptive field is beneficial to the object detection task. Extensive experiments demonstrate that the proposed SpikingYOLOX achieves state-of-the-art performance among other SNN-based object detection methods.",
    "link": "https://ojs.aaai.org/index.php/AAAI/article/view/32137"
  },
  {
    "year": 2024,
    "title": "Event-assisted Blurriness Representation Learning for Blurry Image Unfolding",
    "abstract": "The goal of blurry image deblurring and unfolding task is to recover a single sharp frame or a sequence from a blurry one. Recently, its performance is greatly improved with introduction of a bio-inspired visual sensor, event camera. Most existing event-assisted deblurring methods focus on the design of powerful network architectures and effective training strategy, while ignoring the role of blur modeling in removing various blur in dynamic scenes. In this work, we propose to implicitly model blur in an image by computing blurriness representation with an event-assisted blurriness encoder. The learning of blurriness representation is formulated as a ranking problem based on specially synthesized pairs. Blurriness-aware image unfolding is achieved by integrating blur relevant information contained in the representation into a base unfolding network. The integration is mainly realized by the proposed blurriness …",
    "link": "https://ieeexplore.ieee.org/abstract/document/10702490/"
  },
  {
    "year": 2024,
    "title": "CWSCNet: Channel-Weighted Skip Connection Network for Underwater Object Detection",
    "abstract": "Autonomous underwater vehicles (AUVs) equipped with the intelligent underwater object detection technique is of great significance for underwater navigation. Advanced underwater object detection frameworks adopt skip connections to enhance the feature representation which further boosts the detection precision. However, we reveal two limitations of standard skip connections: 1) standard skip connections do not consider the feature heterogeneity, resulting in a sub-optimal feature fusion strategy; 2) feature redundancy exists in the skip connected features that not all the channels in the fused feature maps are equally important, the network learning should focus on the informative channels rather than the redundant ones. In this paper, we propose a novel channel-weighted skip connection network (CWSCNet) to learn multiple hyper fusion features for improving multi-scale underwater object detection. In …",
    "link": "https://ieeexplore.ieee.org/abstract/document/10684047/"
  },
  {
    "year": 2024,
    "title": "Reversing Structural Pattern Learning with Biologically Inspired Knowledge Distillation for Spiking Neural Networks",
    "abstract": "Spiking neural networks (SNNs) have superb characteristics in sensory information recognition tasks due to their biological plausibility. However, the performance of some current spiking-based models is limited by their structures which means either fully connected or too-deep structures bring too much redundancy. This redundancy from both connection and neurons is one of the key factors hindering the practical application of SNNs. Although Some pruning methods were proposed to tackle this problem, they normally ignored the fact the neural topology in the human brain could be adjusted dynamically. Inspired by this, this paper proposed an evolutionary-based structure construction method for constructing more reasonable SNNs. By integrating the knowledge distillation and connection pruning method, the synaptic connections in SNNs can be optimized dynamically to reach an optimal state. As a result, the structure of SNNs could not only absorb knowledge from the teacher model but also search for deep but sparse network topology. Experimental results on CIFAR100, Tiny-imagenet and DVS-Gesture show that the proposed structure learning method can get pretty well performance while reducing the connection redundancy. The proposed method explores a novel dynamical way for structure learning from scratch in SNNs which could build a bridge to close the gap between deep learning and bio-inspired neural dynamics.",
    "link": "https://dl.acm.org/doi/abs/10.1145/3664647.3680655"
  },
  {
    "year": 2024,
    "title": "RSNN: Recurrent Spiking Neural Networks for Dynamic Spatial-Temporal Information Processing",
    "abstract": "Spiking Neural Networks (SNNs) have great advantages in discrete event data processing because of their binary digital computation form. However, due to the limitation of the current structures of SNNs, the original event data needs to be preprocessed to reduce the time calculation steps and information redundancy. The traditional methods of dividing data into frames lead to the loss of a large amount of time information. In this paper, we proposed an efficient Recurrent Spiking Neural Network (RSNN) to reduce the time domain information loss of original slice samples with the spiking based neural dynamics for processing the dynamic spatial-temporal information. By constructing the Recurrent Spiking Neural Network model, the recurrent structure was used to preprocess slices before it was further input into the spiking structure to enhance the time correlation between slices. In addition, in order to match the two-dimensional spatial structure of data sample frames efficiently, this paper adapts a variation of structures of the recurrent neural network, named Convolution LSTM (CONLSTM). Through experiments on event based datasets such as DVS128-Gesture and CIFAR10-DVS, we find that the proposed model could not only behave better than some other spiking based models but also save energy and power consumption which paves the way for practical applications of neuromorphic hardware.",
    "link": "https://dl.acm.org/doi/abs/10.1145/3664647.3680573"
  },
  {
    "year": 2024,
    "title": "Multi-Task Adaptive Resolution Network for Lymph Node Metastasis Diagnosis From Whole Slide Images of Colorectal Cancer",
    "abstract": "Automated detection of lymph node metastasis (LNM) holds great potential to alleviate the workload of doctors and reduce misinterpretations. Despite the practical successes achieved, effectively addressing the highly complex and heterogeneous tumor microenvironment remains an open and challenging problem, especially when tumor subtypes intermingle and are difficult to delineate. In this paper, we propose a multi-task adaptive resolution network, named MAR-Net, for LNM detection and subtyping in complex mixed-type cancers. Specifically, we construct a resolution-aware module to mine heterogeneous diagnostic information, which exploits the multi-scale pyramid information and adaptively combines multi-resolution structured features for comprehensive representation. Additionally, we adopt a multi-task learning approach that simultaneously addresses LNM detection and subtyping, reducing model …",
    "link": "https://ieeexplore.ieee.org/abstract/document/10733987/"
  },
  {
    "year": 2024,
    "title": "Robust Sensory Information Reconstruction and Classification With Augmented Spikes",
    "abstract": "Sensory information recognition is primarily processed through the ventral and dorsal visual pathways in the primate brain visual system, which exhibits layered feature representations bearing a strong resemblance to convolutional neural networks (CNNs), encompassing reconstruction and classification. However, existing studies often treat these pathways as distinct entities, focusing individually on pattern reconstruction or classification tasks, overlooking a key feature of biological neurons, the fundamental units for neural computation of visual sensory information. Addressing these limitations, we introduce a unified framework for sensory information recognition with augmented spikes. By integrating pattern reconstruction and classification within a single framework, our approach not only accurately reconstructs multimodal sensory information but also provides precise classification through definitive labeling …",
    "link": "https://ieeexplore.ieee.org/abstract/document/10547380/"
  },
  {
    "year": 2024,
    "title": "BAUODNET for Class Imbalance Learning in Underwater Object Detection",
    "abstract": "Underwater object detection is of great significance for various applications in underwater scenes. However, class imbalance issue is still an unsolved bottleneck for current underwater object detection algorithms. It leads to large discrepancies in the detection precision among different classes that the dominant classes with more training data achieve higher precision while the minority classes with less training data achieve much lower precision. In this paper, we propose a balanced underwater object detection network (BAUODNET) to address the class imbalance issue by exploiting two techniques, i.e., the style augmentation technique and the example re-weighting technique. Firstly, we propose a class-wise style augmentation (CWSA) algorithm to augment the training data for the minority classes that generates different colors, textures and contrasts for the minority classes whilst preserving geometry. The …",
    "link": "https://ieeexplore.ieee.org/abstract/document/10693644/"
  },
  {
    "year": 2024,
    "title": "Towards efficient deep spiking neural networks construction with spiking activity based pruning",
    "abstract": "Abstract unavailable. This publication does not provide a summary using scholarly.",
    "link": ""
  },
  {
    "year": 2024,
    "title": "The Balanced Multi-Modal Spiking Neural Networks with Online Loss Adjustment and Time Alignment",
    "abstract": "Optimizing multi-modal learning of SNNs has the advantages of energy efficiency and performance improvements. However, modality imbalance in multi-modal SNNs results in performance decline due to heterogeneity of modalities and temporal inconsistencies across different SNNs branches. In this paper, we propose the Balanced Multi-modal SNNs (BM-SNNs) model, equipped with a novel online loss adjustment (LA) algorithm and time alignment (TA) modules, ultimately achieving balanced training across multiple modalities. LA supervises the learning of uni-modal feature extractors by adding unimodal loss components without additional classifier. Moreover, the modulation factors enable the adaptive adjustment of unimodal learning rate. Furthermore, the proposed TA adopts the optimal timestep for different modalities to avoid information redundancy. Experimental results reveal that BM-SNNs model …",
    "link": "https://ieeexplore.ieee.org/abstract/document/10687515/"
  },
  {
    "year": 2024,
    "title": "Hybrid Spiking Vision Transformer for Event-Based Object Detection",
    "abstract": "Event-based object detection has gradually drawn attention for its high time resolution, high dynamic range, and asynchronous address event representation. Spiking Neural Networks (SNNs) offer distinct advantages, including low energy consumption and rich spatiotemporal dynamics. Therefore, in this study, a novel hybrid spike vision Transformer (HsVT) model is proposed, which combines spatial feature extraction and temporal feature extraction components. The spatial feature extraction module is used to extract the local and global features in the input data, and the temporal feature extraction module is used to capture the time dependencies and long-term patterns in the input sequence. With this combination, HsVT models can better capture spatial and temporal features when processing sequence data, thus improving the modeling ability of complex event-based object detection tasks. Besides, we collect the fall detection datasets and make them public as the benchmark of event-based object detection tasks. The Fall detection dataset with event-based camera provides facial privacy protection and saves memory storage due to the event representation manner. We evaluated the performance of HsVT methods on different model sizes and compared their performance on GEN1 and Fall detection datasets. The experimental results show that the HsVT method has achieved remarkable performance improvement in the event detection task with fewer parameters, and provides an effective solution for the event-based object detection task.",
    "link": "https://papers.ssrn.com/sol3/Delivery.cfm?abstractid=4790563"
  },
  {
    "year": 2024,
    "title": "Efficient spiking neural networks with sparse selective activation for continual learning",
    "abstract": "The next generation of machine intelligence requires the capability of continual learning to acquire new knowledge without forgetting the old one while conserving limited computing resources.  Spiking neural networks (SNNs), compared to artificial neural networks (ANNs), have more characteristics that align with biological neurons, which may be helpful as a potential gating function for knowledge maintenance in neural networks. Inspired by the selective sparse activation principle of context gating in biological systems, we present a novel SNN model with selective activation to achieve continual learning. The trace-based K-Winner-Take-All (K-WTA) and variable threshold components are designed to form the sparsity in selective activation in spatial and temporal dimensions of spiking neurons, which promotes the subpopulation of neuron activation to perform specific tasks. As a result, continual learning can be maintained by routing different tasks via different populations of neurons in the network. The experiments are conducted on MNIST and CIFAR10 datasets under the class incremental setting. The results show that the proposed SNN model achieves competitive performance similar to and even surpasses the other regularization-based methods deployed under traditional ANNs.",
    "link": "https://ojs.aaai.org/index.php/AAAI/article/view/27817"
  },
  {
    "year": 2024,
    "title": "Adaptive deep spiking neural network with global-local learning via balanced excitatory and inhibitory mechanism",
    "abstract": "The training method of Spiking Neural Networks (SNNs) is an essential problem, and how to integrate local and global learning is a worthy research interest. However, the current integration methods do not consider the network conditions suitable for local and global learning, and thus fail to balance their advantages. In this paper, we propose an Excitation-Inhibition Mechanism-assisted Hybrid Learning(EIHL) algorithm that adjusts the network connectivity by using the excitation-inhibition mechanism and then switches between local and global learning according to the network connectivity. The experimental results on CIFAR10/100 and DVS-CIFAR10 demonstrate that the EIHL not only has better accuracy performance than other methods but also has excellent sparsity advantage. Especially, the Spiking VGG11 is trained by EIHL, STBP, and STDP on DVS_CIFAR10, respectively. The accuracy of the Spiking VGG11 model on EIHL is 62.45%, which is 4.35% higher than STBP and 11.40% higher than STDP, and the sparsity is 18.74%, which is 18.74% higher than the other two methods. Moreover, the excitation-inhibition mechanism used in our method also offers a new perspective on the field of SNN learning.",
    "link": "https://openreview.net/forum?id=wpnlc2ONu0"
  },
  {
    "year": 2024,
    "title": "Interpretable Sleep Stage Classification Based on Layer-wise Relevance Propagation",
    "abstract": "Numerous deep learning-based methodologies have been proposed to facilitate automatic sleep stage classification tasks. Nevertheless, the black-box nature of these approaches is one of the skeptical factors hindering clinical application. Toward model interpretability, this study presents a novel interpretable sleep stage classification scheme based on layer-wise relevance propagation (LRP). We first adopt the short-time Fourier transform (STFT) to convert the raw electroencephalogram (EEG) signals to the time-frequency images, which could visually demonstrate EEG patterns of each sleep stage. Moreover, we introduce an efficient convolutional neural network (CNN)-based model, namely MSSENet, that assembles with the multiscale CNN (MSCNN) module and residual squeeze-and-excitation (R-SE) block for the image input. The LRP method is eventually applied to evaluate the contribution of each …",
    "link": "https://ieeexplore.ieee.org/abstract/document/10445753/"
  },
  {
    "year": 2024,
    "title": "Efficient structure slimming for spiking neural networks",
    "abstract": "Spiking neural networks (SNNs) are deeply inspired by biological neural information systems. Compared to convolutional neural networks (CNNs), SNNs are low power consumption because of their spike based information processing mechanism. However, most of the current structures of SNNs are fully connected or converted from deep CNNs which poses redundancy connections. While the structure and topology in human brain systems are sparse and efficient. This article aims at taking full advantage of sparse structure and low power consumption which lie in human brain and proposed efficient structure slimming methods. Inspired by the development of biological neural network structures, this article designed types of structure slimming methods including neuron pruning and channel pruning. In addition to pruning, this article also considers the growth and development of the nervous system. Through iterative …",
    "link": "https://ieeexplore.ieee.org/abstract/document/10391076/"
  },
  {
    "year": 2024,
    "title": "Simultaneously segmenting and classifying cell nuclei by using multi-task learning in multiplex immunohistochemical tissue microarray sections",
    "abstract": "Quantitative analysis of tumor immune microenvironment (TIME) in immunohistochemical (IHC) tissue microarray (TMA) sections is crucial in diagnosis and treatment recommendations for cancer patients. Nuclei segmentation and classification are the prerequisites for the TIME quantification, but it still lacks of robust nuclear quantification models used for IHC histological slides. In this paper, we design an approach for simultaneously segmenting and classifying cell nuclei in multiplex IHC TMA sections. The large TMA tissue core is first divided into a set of small overlapping patches, where cell nuclei are then simultaneously segmented and classified by using our multi-task learning model. The model has one feature encoder with cascaded separable-ResUnit blocks, and three decoder branches that incorporate the Self-Attention modules and DenseUnit blocks to perform nuclear segmentation, classification and …",
    "link": "https://www.sciencedirect.com/science/article/pii/S1746809424002015"
  },
  {
    "year": 2023,
    "title": "Enhancing Adaptive History Reserving by Spiking Convolutional Block Attention Module in Recurrent Neural Networks",
    "abstract": "Spiking neural networks (SNNs) serve as one type of efficient model to process spatio-temporal patterns in time series, such as the Address-Event Representation data collected from Dynamic Vision Sensor (DVS). Although convolutional SNNs have achieved remarkable performance on these AER datasets, benefiting from the predominant spatial feature extraction ability of convolutional structure, they ignore temporal features related to sequential time points. In this paper, we develop a recurrent spiking neural network (RSNN) model embedded with an advanced spiking convolutional block attention module (SCBAM) component to combine both spatial and temporal features of spatio-temporal patterns. It invokes the history information in spatial and temporal channels adaptively through SCBAM, which brings the advantages of efficient memory calling and history redundancy elimination. The performance of our model was evaluated in DVS128-Gesture dataset and other time-series datasets. The experimental results show that the proposed SRNN-SCBAM model makes better use of the history information in spatial and temporal dimensions with less memory space, and achieves higher accuracy compared to other models.",
    "link": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/b8734840bf65c8facd619f5105c6acd0-Abstract-Conference.html"
  },
  {
    "year": 2023,
    "title": "EICIL: Joint Excitatory Inhibitory Cycle Iteration Learning for Deep Spiking Neural Networks",
    "abstract": "Spiking neural networks (SNNs) have undergone continuous development and extensive study for decades, leading to increased biological plausibility and optimal energy efficiency. However, traditional training methods for deep SNNs have some limitations, as they rely on strategies such as pre-training and fine-tuning, indirect coding and reconstruction, and approximate gradients. These strategies lack a complete training model and require gradient approximation. To overcome these limitations, we propose a novel learning method named Joint Excitatory Inhibitory Cycle Iteration learning for Deep Spiking Neural Networks (EICIL) that integrates both excitatory and inhibitory behaviors inspired by the signal transmission of biological neurons. By organically embedding these two behavior patterns into one framework, the proposed EICIL significantly improves the bio-mimicry and adaptability of spiking neuron models, as well as expands the representation space of spiking neurons. Extensive experiments based on EICIL and traditional learning methods demonstrate that EICIL outperforms traditional methods on various datasets, such as CIFAR10 and CIFAR100, revealing the crucial role of the learning approach that integrates both behaviors during training.",
    "link": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/65e876f6a98c6799d0b3145966dd73e2-Abstract-Conference.html"
  },
  {
    "year": 2023,
    "title": "A Review of Image Reconstruction Based on Event Cameras",
    "abstract": "Event cameras are bio-inspired sensors that outputs a stream of events when the brightness change of pixels exceeds the threshold. This type of visual sensor asynchronously outputs events that encode the time, location and sign of the brightness changes. Hence, event cameras offer attractive properties, such as high temporal resolution, very high dynamic range, low latency, low power consumption, and high pixel bandwidth. It can capture information in high-speed motion and high-dynamic scenes, which can be used to reconstruct high-dynamic range and high-speed motion scenes. Brightness images obtained by image reconstruction can be interpreted as a representation, and be used for recognition, segmentation, tracking and optical flow estimation, which is one of the important research directions in the field of vision. This survey first briefly introduces event cameras from their working principle …",
    "link": "https://jeit.ac.cn/en/article/doi/10.11999/JEIT221456?viewType=HTML"
  },
  {
    "year": 2023,
    "title": "Vision transformers for computational histopathology",
    "abstract": "Computational histopathology is focused on the automatic analysis of rich phenotypic information contained in gigabyte whole slide images, aiming at providing cancer patients with more accurate diagnosis, prognosis, and treatment recommendations. Nowadays deep learning is the mainstream methodological choice in computational histopathology. Transformer, as the latest technological advance in deep learning, learns feature representations and global dependencies based on self-attention mechanisms, which is increasingly gaining prevalence in this field. This article presents a comprehensive review of state-of-the-art vision transformers that have been explored in histopathological image analysis for classification, segmentation, and survival risk regression applications. We first overview preliminary concepts and components built into vision transformers. Various recent applications including whole slide …",
    "link": "https://ieeexplore.ieee.org/abstract/document/10190115/"
  },
  {
    "year": 2023,
    "title": "Biologically inspired structure learning with reverse knowledge distillation for spiking neural networks",
    "abstract": "Spiking neural networks (SNNs) have superb characteristics in sensory information recognition tasks due to their biological plausibility. However, the performance of some current spiking-based models is limited by their structures which means either fully connected or too-deep structures bring too much redundancy. This redundancy from both connection and neurons is one of the key factors hindering the practical application of SNNs. Although Some pruning methods were proposed to tackle this problem, they normally ignored the fact the neural topology in the human brain could be adjusted dynamically. Inspired by this, this paper proposed an evolutionary-based structure construction method for constructing more reasonable SNNs. By integrating the knowledge distillation and connection pruning method, the synaptic connections in SNNs can be optimized dynamically to reach an optimal state. As a result, the structure of SNNs could not only absorb knowledge from the teacher model but also search for deep but sparse network topology. Experimental results on CIFAR100 and DVS-Gesture show that the proposed structure learning method can get pretty well performance while reducing the connection redundancy. The proposed method explores a novel dynamical way for structure learning from scratch in SNNs which could build a bridge to close the gap between deep learning and bio-inspired neural dynamics.",
    "link": "https://arxiv.org/abs/2304.09500"
  },
  {
    "year": 2023,
    "title": "ESL-SNNs: An Evolutionary Structure Learning Strategy For Spiking Neural Networks",
    "abstract": "Spiking neural networks (SNNs) have manifested remarkable advantages in power consumption and event-driven property during the inference process. To take full advantage of low power consumption and improve the efficiency of these models further, the pruning methods have been explored to find sparse SNNs without redundancy connections after training. However, parameter redundancy still hinders the efficiency of SNNs during training. In the human brain, the rewiring process of neural networks is highly dynamic, while synaptic connections maintain relatively sparse during brain development. Inspired by this, here we propose an efficient evolutionary structure learning (ESL) framework for SNNs, named ESL-SNNs, to implement the sparse SNN training from scratch. The pruning and regeneration of synaptic connections in SNNs evolve dynamically during learning, yet keep the structural sparsity at a certain level. As a result, the ESL-SNNs can search for optimal sparse connectivity by exploring all possible parameters across time. Our experiments show that the proposed ESL-SNNs framework is able to learn SNNs with sparse structures effectively while reducing the limited accuracy. The ESL-SNNs achieve merely 0.28% accuracy loss with 10% connection density on the DVS-Cifar10 dataset. Our work presents a brand-new approach for sparse training of SNNs from scratch with biologically plausible evolutionary mechanisms, closing the gap in the expressibility between sparse training and dense training. Hence, it has great potential for SNN lightweight training and inference with low power consumption and small memory usage.",
    "link": "https://ojs.aaai.org/index.php/AAAI/article/view/25079"
  },
  {
    "year": 2023,
    "title": "Hierarchical Spiking-Based Model for Efficient Image Classification With Enhanced Feature Extraction and Encoding",
    "abstract": "Thanks to their event-driven nature, spiking neural networks (SNNs) are surmised to be great computation-efficient models. The spiking neurons encode beneficial temporal facts and possess excessive anti-noise properties. However, the high-quality encoding of spatio-temporal complexity and also its training optimization of SNNs are restricted by means of the contemporary problem, this article proposes a novel hierarchical event-driven visual device to explore how information transmits and signifies in the retina the usage of biologically manageable mechanisms. This cognitive model is an augmented spiking-based framework consisting of the function learning capacity of convolutional neural networks (CNNs) with the cognition capability of SNNs. Furthermore, this visual device is modeled in a biological realism way with unsupervised learning rules and advanced spike firing rate encoding methods. We train and …",
    "link": "https://ieeexplore.ieee.org/abstract/document/10003253/"
  },
  {
    "year": 2023,
    "title": "Constructing deep spiking neural networks from artificial neural networks with knowledge distillation",
    "abstract": "Spiking neural networks (SNNs) are well known as the brain-inspired models with high computing efficiency, due to a key component that they utilize spikes as information units, close to the biological neural systems. Although spiking based models are energy efficient by taking advantage of discrete spike signals, their performance is limited by current network structures and their training methods. As discrete signals, typical SNNs cannot apply the gradient descent rules directly into parameters adjustment as artificial neural networks (ANNs). Aiming at this limitation, here we propose a novel method of constructing deep SNN models with knowledge distillation (KD) that uses ANN as teacher model and SNN as student model. Through ANN-SNN joint training algorithm, the student SNN model can learn rich feature information from the teacher ANN model through the KD method, yet it avoids training SNN from scratch when communicating with non-differentiable spikes. Our method can not only build a more efficient deep spiking structure feasibly and reasonably, but use few time steps to train whole model compared to direct training or ANN to SNN methods. More importantly, it has a superb ability of noise immunity for various types of artificial noises and natural signals. The proposed novel method provides efficient ways to improve the performance of SNN through constructing deeper structures in a high-throughput fashion, with potential usage for light and efficient brain-inspired computing of practical scenarios.",
    "link": "http://openaccess.thecvf.com/content/CVPR2023/html/Xu_Constructing_Deep_Spiking_Neural_Networks_From_Artificial_Neural_Networks_With_CVPR_2023_paper.html"
  },
  {
    "year": 2023,
    "title": "Automatic cervical cancer segmentation in multimodal magnetic resonance imaging using an EfficientNet encoder in UNet++ architecture",
    "abstract": "Automatic cervical cancer segmentation in multimodal magnetic resonance imaging (MRI) is essential because tumor location and delineation can support patients' diagnosis and treatment planning. To meet this clinical demand, we present an encoder–decoder deep learning architecture which employs an EfficientNet encoder in the UNet++ architecture (E‐UNet++). EfficientNet helps in effectively encoding multiscale image features. The nested decoders with skip connections aggregate multiscale features from low‐level to high‐level, which helps in detecting fine‐grained details. A cohort of 228 cervical cancer patients with multimodal MRI sequences, including T2‐weighted imaging, diffusion‐weighted imaging, apparent diffusion coefficient imaging, contrast enhancement T1‐weighted imaging, and dynamic contrast‐enhanced imaging (DCE), has been explored. Evaluations are performed by considering either …",
    "link": "https://onlinelibrary.wiley.com/doi/abs/10.1002/ima.22799"
  },
  {
    "year": 2023,
    "title": "A summary of image recognition-relevant multi-layer spiking neural networks learning algorithms",
    "abstract": "Abstract unavailable. This publication does not provide a summary using scholarly.",
    "link": ""
  }
]